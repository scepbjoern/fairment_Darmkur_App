version: "3.9"

services:
  db:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ${DB_DATA_PATH}:/var/lib/postgresql/data
    # Externen Port nur freigeben, wenn nötig:
    # ports:
    #   - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  app:
    build:
      context: ..
      dockerfile: Dockerfile
      args:
        HTTP_PROXY: ${HTTP_PROXY}
        HTTPS_PROXY: ${HTTPS_PROXY}
        NO_PROXY: ${NO_PROXY}
      network: host
    restart: unless-stopped
    environment:
      NODE_ENV: production
      # Aus Einzelwerten zusammengesetzt, keine Secrets im Repo
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?schema=public
      # OpenAI transcription (server runtime)
      # Set OPENAI_API_KEY in your stack/Portainer env so this gets injected at runtime
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      # Optional server default model (fallback if client doesn't send one)
      OPENAI_TRANSCRIBE_MODEL: ${OPENAI_TRANSCRIBE_MODEL:-gpt-4o-mini-transcribe}
      # optional: NEXT_TELEMETRY_DISABLED: "1"
    depends_on:
      - db
    ports:
      - "${APP_PORT:-3000}:3000"
    # Persistente Uploads (Hostpfad -> Container /app/uploads). Siehe .env: PUBLIC_UPLOADS_PATH
    # Beispiel in .env:
    #   PUBLIC_UPLOADS_PATH=../uploads
    volumes:
      - ${PUBLIC_UPLOADS_PATH:-../uploads}:/app/uploads

  backup_db:
    container_name: db-backup
    image: postgres:16
    restart: unless-stopped
    volumes:
      - ${DB_BACKUP_PATH}:/dump
      - /etc/localtime:/etc/localtime:ro
    environment:
      PGHOST: db
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: "${POSTGRES_PASSWORD}"
      PGDATABASE: ${POSTGRES_DB}
      BACKUP_NUM_KEEP: "3"
      BACKUP_FREQUENCY: "8h"
      # Kompression steuerbar: Beispiele
      #   gzip:9   (starke Kompression, langsamer)
      #   lz4      (sehr schnell, etwas groesser)
      #   zstd:15  (sehr gute Ratio, schnell – wenn im Image verlinkt)
      BACKUP_COMPRESS: "gzip:6"
    depends_on:
      db:
        condition: service_healthy
    user: "${UID}:${GID}"
    entrypoint: |
      bash -c 'bash -s << "EOF"
      set -Eeuo pipefail
      log() { printf "[%s] %s\n" "$(date -u +%Y-%m-%dT%H:%M:%SZ)" "$*"; }
      trap "log \"Stop-Signal empfangen, beende Container\"; exit 0" SIGHUP SIGINT SIGTERM

      do_backup() {
        local ts outfile start end compress_opt
        ts=$$(date -u "+%Y-%m-%d_%H-%M-%S")
        log "Timestamp: $$ts"
        outfile="/dump/dump_$${ts}.dump"

        # Kompressionsparameter (PG16+: Methode[:Level] moeglich)
        if [ -n "${BACKUP_COMPRESS:-}" ]; then
          compress_opt=(--compress="${BACKUP_COMPRESS}")
        else
          compress_opt=(--compress=6)
        fi

        log "Backup startet → Datei: ${outfile} (compress: ${BACKUP_COMPRESS:-6})"
        start=$$SECONDS
        if pg_dump -h "$$PGHOST" -U "$$PGUSER" -d "$$PGDATABASE" -Fc \
                  "$${compress_opt[@]}" -f "$$outfile" \
                  2>"/dump/dump_$${ts}.stderr.log"; then
          end=$$SECONDS
          log "Backup OK (Dauer: $$((end-start))s, Groesse: $$(du -h "$$outfile" | awk '"'"'{print $$1}'"'"'))"
          [ -s "/dump/dump_$${ts}.stderr.log" ] || rm -f "/dump/dump_$${ts}.stderr.log"
        else
          end=$$SECONDS
          log "Backup FEHLGESCHLAGEN (Dauer: $$((end-start))s). Details: dump_$${ts}.stderr.log"
          return 1
        fi

        # Rotation
        local KEEP
        KEEP=$${BACKUP_NUM_KEEP:-3}
        shopt -s nullglob
        mapfile -t sorted < <(ls -1t /dump/dump_*.dump 2>/dev/null || true)
        if (("$${#sorted[@]}" > KEEP)); then
          log "Rotation: behalte $$KEEP neueste, entferne $$(( $${#sorted[@]} - KEEP )) aeltere"
          printf "%s\0" "$${sorted[@]:KEEP}" | xargs -0 -r rm --
        fi
      }

      log "Warte auf Datenbank $$PGHOST/$$PGDATABASE …"
      until pg_isready -h "$$PGHOST" -U "$$PGUSER" -d "$$PGDATABASE" >/dev/null 2>&1; do
        sleep 2
      done
      log "Datenbank erreichbar."
      mkdir -p /dump

      # Sofort-Backup beim Start
      if ! do_backup; then
        log "Erster Backup-Versuch fehlgeschlagen; neuer Versuch nach 60s"
        sleep 60
        do_backup || log "Warnung: Start-Backup wieder fehlgeschlagen"
      fi

      # Regelmaessige Backups
      while true; do
        sleep $${BACKUP_FREQUENCY:-8h}
        do_backup || log "Warnung: geplanter Backup-Versuch fehlgeschlagen"
      done
      EOF'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
      - "diun.enable=false"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h $$PGHOST -U $$PGUSER -d $$PGDATABASE"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  default:
    name: fairment_network
    ipam:
      config:
        - subnet: 172.40.20.0/24