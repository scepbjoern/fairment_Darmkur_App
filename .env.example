# OpenAI transcription
# Server-side API key (required)
OPENAI_API_KEY=
# Optional: server default model
OPENAI_TRANSCRIBE_MODEL=gpt-4o-mini-transcribe
# Client-side defaults (these are exposed to the browser)
NEXT_PUBLIC_OPENAI_TRANSCRIBE_MODEL=gpt-4o-mini-transcribe

# TogetherAI transcription
TOGETHERAI_API_KEY=
# Server default model
TOGETHERAI_TRANSCRIBE_MODEL=openai/whisper-large-v3
# Client-side default (exposed to browser)
NEXT_PUBLIC_TOGETHERAI_TRANSCRIBE_MODEL=openai/whisper-large-v3
# Comma-separated list of selectable models in the UI
NEXT_PUBLIC_TRANSCRIBE_MODELS=openai/whisper-large-v3,gpt-4o-mini-transcribe,gpt-4o-transcribe

# PostgreSQL connection for Prisma
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/fairment_darmkur?schema=public"

## Image processing (used by /api/notes/[noteId]/photos)
# Maximum dimensions for uploaded images. Images are resized to fit within these bounds.
IMAGE_MAX_WIDTH=1600
IMAGE_MAX_HEIGHT=1600

# Output format for processed images: webp | png | jpeg
IMAGE_FORMAT=webp

# Quality (1-100) for lossy formats (webp/jpeg). Ignored for png.
IMAGE_QUALITY=80

# Map the public uploads folder in docker-compose (host path -> container /app/public/uploads)
# DEPRECATED comment above. We now serve uploads via a dynamic route and store files under /app/uploads.
# Example: on your host, set a persistent path where images should be stored
# PUBLIC_UPLOADS_PATH=../uploads

# Optional: override uploads base directory inside the app (defaults to process.cwd()/uploads => /app/uploads in Docker)
# UPLOADS_DIR=/app/uploads
